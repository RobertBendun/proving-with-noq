= Proving with Noq: Derivatives
:toc:
:date: 2023-11-02

== Why?

I recently watched https://www.youtube.com/watch?v=xuxsjWWg288[video by Michael Penn],
when he showed how to define derivatives on polynomials as only object that satisfies certain properties.

Seeing that this proof is quite simple I wondered if it would be easy to translate to https://github.com/tsoding/Noq[Noq], which is an symbolic expression transformer, sort-of an alternative to writing proofs with pen and paper.

This post is written in https://en.wikipedia.org/wiki/Literate_programming[literate programming] style, so you can extract code from it and run it without modification in Noq.
See https://github.com/RobertBendun/proving-with-noq#proving-with-noq[associated git repository] for details.

== Noq

I really like Noq.
Despite beeing self-proclaimed math-enjoyer I didn't like many of math classes in my education.
Teachers and classmates when doing algebra on a blackboard would always skip some steps and take some shortcuts to keep equations on the board, which made them harder to reason about - you have to rediscover what transformations have taken place since they were always _implicit_.

That's where Noq comes in - by beeing the tool that you can express symbolic transformations in, each step of proof or calculation is explicit - Noq doesn't infer anything, only matches the patterns that you have provided.
I am really interested in how it can be used in math education, maybe as a suplementary measure.

=== Quick introduction

Primary construct in Noq are _rules_: transformations that can pattern match on currently held equation.
For example rule `f(A + B) = f(A) + f(B)` will transform function of sum to sum of functions.
Note the different case - uppercase variables are matched, lowercase symbols stay.
Rules can be named, using `name +::+ rule` syntax.

Rules can be used in _shaping_, a process of equation transformation. Shaping is another syntax for rule, but with justification attach to it (replacing `= rhs` part from `lhs = rhs` rule): `f(A + B) { ... }`.
Inside curly braces we pattern match using rules. Pattern matches are applied using strategies, for example `0` replaces first match and `all` replaces all matches.
Rules can be applied with reverse by using `!`.

For better documentation look in https://github.com/tsoding/Noq[Noq repository], now let's get back to the topic.

== Derivatives

We claim that the only linear map from polynomials to polynomials named `d`
that has these two properties:
[source]
----
derivative_constant :: d(X) = 1
derivative_mult :: d(X*Y) = d(X)*Y + X*d(Y)
----
is derivative.
As it will be shown below, this is enough to have working derivatives for polynomials.

[NOTE]
====
`derivative_constant` rule matches on any expression - Noq does not have ability to recognize type of expression (can't see difference between scalar and variable, number and expression).
Be _careful_ when applying rules, Noq will not prevent from making invalid transformations, that are syntacticly correct.
====

=== Power rule proof

The only proof that we need to do is the power rule (derivative of variable to some constant), defiened as:

[source]
----
derivative_power_rule :: d(X^N) = N*X^(N - 1)
----

First we need some prior math knowladge:

[source]
----
// Peano axioms
refl :: X == X = true
trans :: and(A == B, A == C) = B == C

// Multiplication
mult :: (N + 1)*X = N*X + X
mult_comm :: X*Y = Y*X
mult_assoc :: (A*B)*C = A*(B*C)
mult_id :: X*1 = X
mult_zero :: 0*X = 0
double :: X + X = 2*X

exponents_sum :: X^(A + B) = X^A*X^B
----

.Exponents sum proof
[%collapsible]
====
[source]
----
exponents_sum_base :: X^(A + 0) == X^A*X^0 {
    X^0 = 1 | 0
    mult_id | 0
    A + 0 = A | 0
    refl | 0
}

exponents_sum_hyp :: X^(A + b) = X^A*X^b
sum_assoc :: (A + B) + C = A + (B + C)
exp :: X^(A + 1) = X^A*X

exponents_sum_ind :: X^(A + (b + 1)) == X^A*X^(b + 1) {
    exp | 0
    mult_assoc |! 0
    exponents_sum_hyp |! 0
    exp |! 0
    sum_assoc | 0
    refl | 0
}
----
====

The rules above are mostly in Noq standard library, but to have post self-contained we assume that they are correct and skip their construction from Peano axioms.

We will prove power rule using induction.

==== Base case

To solve the base case we will utilize the fact, that only for `X = 0` the equation `X == A*X` is true.

[source]
----
derivative_power_rule_base :: d(X^0) == 0*d(X) {
    mult_zero | 0
    X^0 = 1 | 0
    X == Y = and(X == X, X == Y) | 0
    mult_id |! 8
    derivative_mult | 0
    mult_comm | 1
    double | 0
    mult_id | 0
    X == A*X = X == 0 | 0
    trans | 0
    refl | 0
}
----

One interesing fragment from this proof that is required to be fully contained in the language (and not for example in comments) is usage of `and` to store previous knowladge.
As can be https://youtu.be/xuxsjWWg288?si=_m82FiS4Su_Z8lYp&t=435[seen in the video], we use previous expression to infer meaning to a new one.
In Noq, as in most https://en.wikipedia.org/wiki/Computer_language[computer languages], we must store prior knowladge somewhere to use it later. In this case we somewhat fork our equality to two, which allows us to join (with `trans`) later.

.Rule `X == Y = and(X == X, X == Y)`
[%collapsible]
====
[source]
----
and_id :: and(true, X) = X
fork :: X == Y {
    and_id |! 0
    refl |! 0
}
----
====

==== Inductive step

We construct induction hypothesis:

[source]
----
derivative_power_rule_hyp :: d(X^n) = n*X^(n - 1)
----

It would be tempting to use `derivative_power_rule` directly, instead of hypothesis.
In fact we can, but we must be very carefull to match only what we can match (limit ourself to only using the hypothesis and not any occurance of this sequence of symbols).
By expressing the hypothesis directly we have more confidence that our proof is valid.

.Missing hypothesis definition gone wrong
[%collapsible]
====

We can see how misusing rule definition as hypothesis can go wrong with simple proof of commutativity of sum identity addition.
We are using https://en.wikipedia.org/wiki/Peano_axioms[Peano axioms].

[source]
----
sum_id :: 0 + A = A
sum :: s(A) + B = s(A + B)
sum_id_comm :: A + 0 = A

sum_id_comm_base :: 0 + 0 == 0 {
    sum_id | 0
    refl | 0
}

sum_id_comm_ind_wrong :: s(A) + 0 == s(A) {
    sum_id_comm | 0
    refl | 0
}
----

We can see what went wrong - we use what we are trying to prove as fact, not our induction hypothesis.
If we limit ourself, by constructing proper hypothesis this mistake wouldn't happen.

[source]
----
sum_id_comm_hyp :: a + 0 = a
sum_id_comm_ind_good :: s(a) + 0 == s(a) {
    sum | 0
    sum_id_comm_hyp | 0
    refl | 0
}
----
====

[source]
----
derivative_power_rule_ind :: d(X^(n + 1)) == (n + 1)*X^n {
    exponents_sum | 0
    derivative_mult | 0
    X^1 = X | all
    derivative_constant | 1
    derivative_power_rule_hyp | 0
    mult_assoc | 0
    X = X^1 | 10
    exponents_sum |! 0
    (X - A) + A = X | 0
    mult_id | 0
    mult |! 0
    refl | 0
}
----

=== Random polynomial transformation

To transform any polynomial we need to introduce https://en.wikipedia.org/wiki/Linear_map#Definition_and_first_consequences[linear map rules]:

[source]
----
linear_map_addition :: F(U + V) = F(U) + F(V)
linear_map_scalar_mult :: F(S * X) = S * F(X)
----

Then we can calculate derivative of any polynomial:

[source]
----
random_polynomial_derivative :: d(2*x^3 + 4*x^2) {
    linear_map_addition | 0
    linear_map_scalar_mult | all
    derivative_power_rule | all
    3 - 1 = 2 | 0
    2 - 1 = 1 | 0
    mult_assoc |! all
    2*3 = 6 | 0
    4*2 = 8 | 0
}
----
